# Аналіз предметної області

## Вступ

У даному документі буде коротка інформація про аналіз предметної області, пов’язаної з системами аналізу медіа контенту. Ми розглянемо різні підходи та варіанти вирішення завдання, порівняємо між собою вже існуючі сервіси, які використовуються для вирішення подібних проблем, та прийдемо до висновку, чи варто створювати нову інформаційну систему, або ж модифікувати вже існуючу.


## Основні визначення

*[Розділ містить визначення термінів та скорочень, які використовуються при аналізі предметної області.]*

## Підходи та способи вирішення завдання

Популярність контент-аналізу ґрунтується на тому, що цей метод дозволяє виміряти людську поведінку. На відміну від опитувань, контент-аналіз вимірює не те, що люди говорять, що зробили чи зроблять, а те, що вони справді зробили.

Може використовуватися як основний метод дослідження (наприклад, контент-аналіз тексту при дослідженні політичної спрямованості газети), в поєднанні з іншими методами (наприклад, в дослідженні ефективності функціонування засобів масової інформації), допоміжний або контрольний (наприклад, при класифікації відповідей на відкриті запитання анкет).

### Виділяють два основних типи контент-аналізу:

* кількісний - *націлений на виявлення частоти окремих тем, слів або символів, що містяться у тексті;*

* якісний - *фіксує нетривіальні висловлювання, мовні інтонації з розумінням цінності змісту повідомлення;*

До кількісних належать:
* Текст майнінг (найпоширеніший метод дослідження)
* Контент аналіз
* Аналіз природної мови

До якісних методів належать:
* Дискурс-аналіз
* Традиційні методи аналізу
* Феноменологічний аналіз

Однією з проблем при проектуванні системи аналізу медіа-контенту є необхідність вибору правильного підходу до вирішення задачі. На сьогоднішній день існує багато напрямів і стратегій, а також сучасних рішень для завдань у цьому напрямі.

### Виділяють два основних етапи роботи систем аналізу медіа-контенту: 

* Перший етап – збір інформації.<br>
  Найбільш оптимальним методом швидкого та якісного збору потрібної інформації є парсинг (синтаксичний аналіз). При великих потоках інформації доцільним є використання технології Big Data.

* Другий етап – оброка інформації.<br>
  Весь зібраний матеріал необхідно обробити (відсортувати) для того щоб його можна було подати у зручному для сприйняття вигляді. З цією метою використовується контент-аналіз.

[Parsing](https://en.wikipedia.org/wiki/Parsing) – послідовний синтаксичний аналіз інформації, розміщеної на веб-сторінці за допомогою спеціально написаних програм/скриптів здатних швидко аналізувати контент та знаходити необхідну інформацію.

[Big Data](https://en.wikipedia.org/wiki/Big_data) – група технологій та методів, за допомогою яких аналізують та обробляють велику кількість даних (як структурованих так і неструктурованих), що не піддається обробці класичними способами через занадто великий об'єм.

[Data Mining](https://en.wikipedia.org/wiki/Data_mining) – процес напівавтоматичного аналізу великих баз даних з метою пошуку корисних фактів. Зазвичай поділяють на задачі класифікації, моделювання та прогнозування.

[Text Mining](https://en.wikipedia.org/wiki/Text_mining) – напрям інтелектуального аналізу даних (англ. Data Mining) та штучного інтелекту, метою якого є отримання інформації з колекцій текстових документів, ґрунтуючись на застосуванні ефективних, у практичному плані, методів машинного навчання та обробки природної мови. Інтелектуальний аналіз тексту використовує всі ті ж підходи до перероблювання інформації, що й інтелектуальний аналіз даних, однак різниця між цими напрямками проявляється лише в кінцевих методах, а також у тому, що інтелектуальний аналіз даних має справу зі сховищами та базами даних, а не електронними бібліотеками та корпусами текстів.

[Deep Learning](https://en.wikipedia.org/wiki/Deep_learning) – це галузь машинного навчання, що ґрунтується на наборі алгоритмів, які намагаються моделювати високорівневі абстракції в даних, застосовуючи глибинний граф із декількома обробними шарами, що побудовано з кількох лінійних або нелінійних перетворень.

[TensorFlow](https://www.tensorflow.org/) – відкрита програмна бібліотека для машинного навчання цілій низці задач, розроблена компанією Google для задоволення її потреб у системах, здатних будувати та тренувати нейронні мережі для виявляння та розшифровування образів та кореляцій, аналогічно до навчання й розуміння, які застосовують люди.

[Apache Lucene](https://lucene.apache.org/) – це бібліотека, що дозволяє організувати повнотекстовий пошук по безлічі документів, тобто пошук з використанням заданих ключових слів. Основна реалізація даної бібліотеки написана на Java, але в той же час існують порти цієї бібліотеки на інші мови і платформи.

[Sphinx](https://sphinxsearch.com/) – система повнотекстового пошуку, відмінною особливістю якої є висока швидкість індексації та пошуку, а також інтеграція з існуючими СУБД (MySQL, PostgreSQL) та наявність API для поширених мов веб-програмування.

[Elasticsearch](https://www.elastic.co/) – пошуковий сервер, розроблений на базі Lucene. Надає розподілений, мультиарендний повнотекстовий пошуковий рушій з HTTP вебінтерфейсом і підтримкою безсхемних JSON документів.

[Full text search](https://en.wikipedia.org/wiki/Full-text_search) - це більш вдосконалений спосіб пошуку в базі даних. Full text search швидко знаходить усі екземпляри терміна (слова) у таблиці, не потребуючи сканування рядків і не знаючи, в якому стовпці зберігається термін. Full text search працює за допомогою текстових індексів.

[Tokenization](https://www.tokenex.com/resource-center/what-is-tokenization) - процес заміни конфіденційного елемента даних на неконфіденційну еквівалент, званий токеном, який не має самостійного сенсу / значення для зовнішнього або внутрішнього використання. Токен - це посилання (тобто ідентифікатор), яка зіставляється з конфіденційними даними через систему токенізаціі. Зіставлення вихідних даних з токеном використовує методи, які унеможливлюють зворотне перетворення токенов в вихідні дані поза системою токенізаціі, наприклад, з використанням токенов, створених за допомогою випадкових чисел.
## Порівняльна характеристика існуючих засобів вирішення завдання

*[Розділ містить опис існуючих програм, інформаційних систем, сервісів, тощо, призначених для вирішення 
завдання. Дається порівняльна характеристика властивостей FURPS:*
- *Functionality (функциональні вимоги)*
- *Usability (вимоги до зручності роботи)*
- *Reliability (вимоги до надійності)*
- *Performance (вимоги до продуктивності)*
- *Supportability (вимоги до підтримки)*

 *(у вигляді таблиці).]*

## Висновки

Зробивши висновки, можна переконатися у доцільності розробки нової інформаційної системи аналізу медіа-контенту. Незважаючи на те що представленні у таблиці системи мають доволі непоганий функціонал та інтерфейс, вони всі платні, хоча і є тріал-період. Також вони всі не підтримують українську мову, що було б непогано для вітчизняних компаній. Отже, задача нашої команди є створення системи, що ввібрала би все найкраще з інших систем та була зрозумілою для користувача.

## Посилання

*[Розділ містить повний список всіх документів, про які згадується.]*
